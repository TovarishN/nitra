using Nitra.Internal;
using Nitra.Internal.Recovery;
using Nitra.Runtime;
using Nitra.Runtime.GraphUtils;
using Nitra.Runtime.Reflection;

using Nemerle;
using Nemerle.Assertions;
using Nemerle.Collections;
using Nemerle.Text;
using Nemerle.Utility;
using Nemerle.Imperative;

using System;
using System.Diagnostics;
using System.Threading;
using System.Linq;

using System.Xml.Linq;
using SCG = System.Collections.Generic;

namespace Nitra
{
#if !PARSER_DEBUG
  //[DebuggerStepThroughAttribute]
#endif
  public sealed class CompositeGrammar
  {
    private static mutable _idCounter : int = 0;

    internal RuntimeId               : int { get; default Interlocked.Increment(ref _idCounter); }

    public  Grammars                 : Set[GrammarDescriptor];
    public  ParserHost               : ParserHost;
    private SimpleRuleParsers        : Hashtable[SimpleRuleDescriptor, SimpleRuleParser];
    private ExtensibleRules          : Hashtable[ExtensibleRuleDescriptor, ExtensibleRuleParserData] = Hashtable();
    private Tokens                   : SCG.Dictionary[object, TokenParser] = SCG.Dictionary();
    private VoidTokens               : SCG.Dictionary[object, TokenParser] = SCG.Dictionary();

    public Simples     : Seq[SimpleRuleParser];
    public Prefixs     : Seq[ExtensionRuleParser];
    public Postfixs    : Seq[ExtensionRuleParser];
    public Extensibles : Seq[ExtensibleRuleParser];

    public Add(grammarDescriptor : GrammarDescriptor) : CompositeGrammar
    {
      this.ParserHost.AddGrammar(this, grammarDescriptor)
    }

    internal this([NotNull] parserHost : ParserHost)
    {
      Grammars = Set();
      SimpleRuleParsers = Hashtable();
      ParserHost = parserHost;
    }

    internal this([NotNull] parserHost : ParserHost, [NotNull] grammars : Set[GrammarDescriptor], [NotNull] ruleIdBuilder : RuleIdBuilder)
    {
      Grammars = grammars;
      ParserHost = parserHost;

      MakeBindingPowerMap();

      def rules = Grammars.SelectMany(gd => gd.Rules).NToArray();

      def extensionRuleDescriptors = rules
        .OfType.[ExtensionRuleDescriptor]()
        .Grouping(rd => (rd.BaseRule, rd))
        .Map((baseRd, extetions) =>
        {
          def prefix = extetions.OfType.[PrefixRuleDescriptor]().NToArray();
          def postfix = extetions.OfType.[PostfixRuleDescriptor]().MapToArray(rd => (rd, GetBindingPower(baseRd, rd.BindingPower)));
          Array.Sort.[PostfixRuleDescriptor * int](postfix, (((_, lbp), (_, rbp)) => lbp.CompareTo(rbp)));
          (baseRd, (prefix, postfix.MapToArray((rd, _bp) => rd)))
        });

      foreach (extensibleRule in rules.OfType.[ExtensibleRuleDescriptor]())
      {
        def (prefixDescriptors, postfixDescriptors) = extensionRuleDescriptors.GetValueOrDefault(extensibleRule, (array[], array[]));
        ExtensibleRules[extensibleRule] = ExtensibleRuleParserData(this, extensibleRule, prefixDescriptors, postfixDescriptors, ruleIdBuilder);
      }

      SimpleRuleParsers = Hashtable(rules
        .OfType.[SimpleRuleDescriptor]()
        .Map(rd => (rd, rd.NewParser(this, ruleIdBuilder))));

      foreach (extensibleRule in ExtensibleRules)
        extensibleRule.Value.Init(ruleIdBuilder);

      foreach (kv in SimpleRuleParsers)
        kv.Value.Init(ruleIdBuilder);

      foreach (extensibleRule in ExtensibleRules)
        _ = GetExtensibleRuleParser(extensibleRule.Key, "0");

      InitTokens();

      Simples     = SimpleRuleParsers.Values.ToArray();
      def extensibleRules = ExtensibleRules.Values;
      Prefixs     = extensibleRules.Map(data => data.PrefixParsers).Flatten().ToArray();
      Postfixs    = extensibleRules.Map(data => data.PostfixParsers).Flatten().ToArray();
      Extensibles = extensibleRules.Map(data => data.Parsers.Filter(_ != null)).Flatten().ToArray();

      InitMandatoryTokenCount();
      InitConditionalEmpty();

      foreach (ruleParser in Simples)     ruleParser.ParsingSequence = ParsingSequence.CreateSimple(ruleParser, ruleIdBuilder, this);
      foreach (ruleParser in Prefixs)     ruleParser.ParsingSequence = ParsingSequence.CreateExtension(ruleParser, ruleIdBuilder, this);
      foreach (ruleParser in Postfixs)    ruleParser.ParsingSequence = ParsingSequence.CreateExtension(ruleParser, ruleIdBuilder, this);
      foreach (ruleParser in Extensibles) ruleParser.ParsingSequence = ParsingSequence.CreateExtensible(ruleParser, ruleIdBuilder, this);

      CollectTokens();
      CollectFirstTokens(ruleIdBuilder);
    }

    private BindingPowerMap : Hashtable[ExtensibleRuleDescriptor, Hashtable[string, int]] = Hashtable();
    public GetBindingPower(rd : ExtensibleRuleDescriptor, bpName : string) : int
    {
      mutable map;
      def defaultBP(bpName)
      {
        if (bpName.StartsWith("+"))
          3
        else
          2
      }
      def bp = if (BindingPowerMap.TryGetValue(rd, out map))
      {
        mutable bp;
        if (map.TryGetValue(bpName, out bp))
          bp
        else
          defaultBP(bpName)
      }
      else
        defaultBP(bpName);
      bp
    }

    [Record]
    private class Precedence : GraphNodeWithConnections[Precedence]
    {
      public Name : string;
    }

    private MakeBindingPowerMap() : void
    {
      def allPrecedences = Hashtable();
      def getPrecedence(descriptor, name)
      {
        mutable precedences;
        unless (allPrecedences.TryGetValue(descriptor, out precedences))
        {
          precedences = Hashtable();
          allPrecedences.Add(descriptor, precedences);
        }
        mutable precedence;
        unless (precedences.TryGetValue(name, out precedence))
        {
          precedence = Precedence(name);
          precedences.Add(name, precedence);
        }
        precedence
      }
      foreach (grammar in Grammars)
      {
        foreach ((rd, allPrecedences) in grammar.AllPrecedences)
          foreach (name in allPrecedences)
            _ = getPrecedence(rd, name);
        foreach ((rd, relations) in grammar.BindingPowerRelations)
          foreach ((loName, hiName) in relations)
          {
            def lo = getPrecedence(rd, loName);
            def hi = getPrecedence(rd, hiName);
            _ = hi.AddConnection(lo);
          }
      }
      foreach ((descriptor, precedences) in allPrecedences.KeyValuePairs)//TODO: генерация сообщений об ошибках в случае циклов и не полной упорядоченности приоритетов.
      {
        def bpMap = Hashtable();
        bpMap["0"]  = 0;
        bpMap["+0"] = 1;
        def groups = GraphAlgorithms.FindStronglyConnectedComponents(precedences.Values);
        foreach ((group, bindingPower) in GraphAlgorithms.FindMaximalDistanceToLeafInDAG(groups))
        {
          def e = group.Nodes.GetEnumerator(); // 'foreach' causes invalid IL
          while (e.MoveNext())
          {
            def precedence = e.Current;
            bpMap[precedence.Name]       = (bindingPower + 1) * 2;
            bpMap["+" + precedence.Name] = (bindingPower + 1) * 2 + 1;
          }
        }
        BindingPowerMap.Add(descriptor, bpMap);
      }
    }

    private InitConditionalEmpty() : void
    {
      mutable updated = true;
      def seqMap = Hashtable.[_, SCG.HashSet[SubruleInfo.PredicateDelegate]]();
      def subruleMap = Hashtable.[_, SCG.HashSet[SubruleInfo.PredicateDelegate]]();
      def initConditionalEmpty(seq)
      {
        def seqPredicates = seqMap.GetValue(seq, SCG.HashSet);
        def seqCount = seqPredicates.Count;
        mutable seqHead = true;
        foreach (subrule in seq.Subrules)
        {
          def subrulePredicates = subruleMap.GetValue(subrule, SCG.HashSet);
          def subruleCount = subrulePredicates.Count;
          subrulePredicates.UnionWith([subrule.HeadPredicate, null]);
          match (subrule)
          {
            | Empty                        => ()
            | RegularCall                  => ()
            | TokenString                  => ()
            | ExtensibleCall    as subrule =>
              when (subrule.CanParseEmptyString)
                subrulePredicates.UnionWith(subrule.RuleParser.PrefixRules.SelectMany(r => { initConditionalEmpty(r.SequenceInfo); seqMap[r.SequenceInfo] }));

            | SimpleCall        as subrule =>
              when (subrule.CanParseEmptyString)
              {
                initConditionalEmpty(subrule.RuleParser.SequenceInfo);
                subrulePredicates.UnionWith(seqMap[subrule.RuleParser.SequenceInfo]);
              }

            | Option            as subrule =>
              initConditionalEmpty(subrule.Rule);

            | List              as subrule =>
              initConditionalEmpty(subrule.Item);

            | ListWithSeparator as subrule =>
              initConditionalEmpty(subrule.Item);
              initConditionalEmpty(subrule.Separator);

            | ListItem                     => assert(false);
            | Marker                       => assert(false);
          }
          updated = updated || subrulePredicates.Count != subruleCount;
          when (seqHead)
            seqPredicates.UnionWith(subrulePredicates);
          seqHead = seqHead && subrule.CanParseEmptyString;
        }
        updated = updated || seqPredicates.Count != seqCount;
      }
      while (updated)
      {
        updated = false;
        foreach (ruleParser in Simples)                    initConditionalEmpty(ruleParser.SequenceInfo);
        foreach (ruleParser in Prefixs)                    initConditionalEmpty(ruleParser.SequenceInfo);
        foreach (ruleParser in Postfixs)                   initConditionalEmpty(ruleParser.SequenceInfo);
      }
      foreach ((subrule, predicates) when predicates.Count > 1 in subruleMap.KeyValuePairs)
      {
        _ = predicates.Remove(null);
        subrule.ConditionalEmpty = predicates.ToArray();
      }
    }

    private InitMandatoryTokenCount() : void
    {
      //n >= 0 означает ровно n токенов
      //n < 0 означает ~n или больше токенов
      def addT(mt1 : int, mt2 : int) : int
      {
        if (mt1 < 0) if (mt2 < 0) ~(~mt1 + ~mt2)
                     else         ~(~mt1 +  mt2)
        else         if (mt2 < 0) ~( mt1 + ~mt2)
                     else          ( mt1 +  mt2)
      }

      def minT(mt1 : int, mt2 : int) : int
      {
        if (mt1 < 0) if (mt2 < 0) if (~mt1 < ~mt2) mt1 else mt2
                     else         if (~mt1 <  mt2) mt1 else mt2
        else         if (mt2 < 0) if (mt1 <= ~mt2) mt1 else mt2
                     else         if (mt1 <=  mt2) mt1 else mt2
      }

      def mulT(mt : int, times : int) : int
      {
        if (times == 0)
          0
        else if (mt < 0)
          ~((~mt) * times)
        else
          mt * times;
      }

      def initSequenceInfo(seq)
      {
        seq.MandatoryTokenCount = ~0;
        foreach (subrule in seq.Subrules)
        {
          subrule.MandatoryTokenCount = ~0;
          match (subrule)
          {
            | ListItem => assert(false)
            | Empty | RegularCall | TokenString | ExtensibleCall | SimpleCall => ()
            | Option            as subrule => initSequenceInfo(subrule.Rule);
            | List              as subrule => initSequenceInfo(subrule.Item);
            | ListWithSeparator as subrule => initSequenceInfo(subrule.Item); initSequenceInfo(subrule.Separator);
            | Marker                       => assert(false);
          }
        }
      }

      foreach (ruleParser in Simples)                    initSequenceInfo(ruleParser.SequenceInfo);
      foreach (ruleParser in Prefixs)                    initSequenceInfo(ruleParser.SequenceInfo);
      foreach (ruleParser in Postfixs)                   initSequenceInfo(ruleParser.SequenceInfo);
      foreach (ruleParserData in ExtensibleRules.Values) ruleParserData.MandatoryTokenCount = ~0;

      mutable updated = true;
      while (updated)
      {
        updated = false;
        def updateSequenceInfo(seq)
        {
          mutable count = 0;
          foreach (subrule in seq.Subrules)
          {
            subrule.MandatoryTokenCount = match (subrule)
            {
              | ListItem                     => assert(false);
              | Empty                        => 0;
              | RegularCall       as subrule => if (subrule.CanBeEmpty) 0 else 1;
              | TokenString       as subrule => if (subrule.Str == "") 0 else 1;
              | ExtensibleCall    as subrule =>
                if (subrule.RuleParser.Descriptor.IsTokenRule)
                  minT(subrule.RuleParser.MandatoryTokenCount, 1);
                else
                  subrule.RuleParser.MandatoryTokenCount

              | SimpleCall        as subrule =>
                if (subrule.RuleParser.Descriptor.IsTokenRule)
                  minT(subrule.RuleParser.SequenceInfo.MandatoryTokenCount, 1);
                else
                  subrule.RuleParser.SequenceInfo.MandatoryTokenCount

              | Option            as subrule =>
                updateSequenceInfo(subrule.Rule);
                0;

              | List              as subrule =>
                updateSequenceInfo(subrule.Item);
                mulT(subrule.Item.MandatoryTokenCount, subrule.Min);

              | ListWithSeparator as subrule =>
                updateSequenceInfo(subrule.Item);
                updateSequenceInfo(subrule.Separator);
                match (subrule.Min)
                {
                  | 0 => 0
                  | 1 => subrule.Item.MandatoryTokenCount
                  | c => addT(mulT(subrule.Item.MandatoryTokenCount, c),  mulT(subrule.Separator.MandatoryTokenCount, (c - 1)))
                }

              | Marker                       => assert(false);
            }
            count = addT(count, subrule.MandatoryTokenCount);
          }
          updated = updated || count != seq.MandatoryTokenCount;
          seq.MandatoryTokenCount = count;
        }
        foreach (ruleParser in Simples)    updateSequenceInfo(ruleParser.SequenceInfo);
        foreach (ruleParser in Prefixs)    updateSequenceInfo(ruleParser.SequenceInfo);
        foreach (ruleParser in Postfixs)   updateSequenceInfo(ruleParser.SequenceInfo);
        foreach (ruleParserData in ExtensibleRules.Values)
        {
          mutable min = ~int.MaxValue;
          foreach (ruleParser in ruleParserData.PrefixParsers)
          {
            def cur = ruleParser.SequenceInfo.MandatoryTokenCount;
            min = minT(min, cur);
          }
          otherwise
            min = 100; // TODO: Fixme WolfHound. // We use 100 when int.MaxValue can lead to overflow exception

          updated = updated || min != ruleParserData.MandatoryTokenCount;
          ruleParserData.MandatoryTokenCount = min;
        }
      }
    }

    private CollectTokens() : void
    {
      def consumeErrorTokensToProcess = SCG.Stack();

      def updateTokens(parsingSequence : ParsingSequence)
      {
        when (parsingSequence.CanConsumeErrorTokens)
          consumeErrorTokensToProcess.Push(parsingSequence);

        def addToken(state, key : object)
        {
          mutable token;
          when (Tokens.TryGetValue(key, out token))
            _ = token.Callers.Add(ParsingCallerInfo(parsingSequence, state.Id))
        }
        foreach (state in parsingSequence.States)
        {
          | Predicate                  => ()
          | Simple            as state => _ = state.RuleParser.ParsingSequence.Callers.Add(ParsingCallerInfo(parsingSequence, state.Id)); when (state.RuleParser.IsTokenRule) addToken(state, state.RuleParser)
          | Extensible        as state => _ = state.RuleParser.ParsingSequence.Callers.Add(ParsingCallerInfo(parsingSequence, state.Id)); when (state.RuleParser.IsTokenRule) addToken(state, state.RuleParser)
          | List              as state1 with (seq = state1.Sequence, id = state1.Id)
          | ListWithSeparator as state2 with (seq = state2.Sequence, id = state2.Id)
          | Subsequence       as state3 with (seq = state3.Sequence, id = state3.Id)
          | DynamicExtensible as state4 with (seq = state4.Sequence, id = state4.Id) => _ = seq.Callers.Add(ParsingCallerInfo(parsingSequence, id)); updateTokens(seq);
          | Scan              as state =>
            match (state.SubruleInfo)
            {
              | RegularCall as subrule => addToken(state, subrule.Descriptor)
              | TokenString as subrule => addToken(state, subrule.Str)
              | Empty                  => ()
              | _                      => assert3(false)
            }

          | DynamicExtensibleItem as state =>
            foreach (parser in state.RuleParser.PrefixRules)
              _ = parser.ParsingSequence.Callers.Add(ParsingCallerInfo(parsingSequence, state.Id));

          | ExtensionPrefix  as state =>
            foreach (parser in state.RuleParser.PrefixRules)
              _ = parser.ParsingSequence.Callers.Add(ParsingCallerInfo(parsingSequence, state.Id));

          | ExtensionPostfix as state =>
            foreach (parser when state.RuleParser.FirstPostfixRuleId <= parser.RuleId in state.RuleParser.PostfixRules)
              _ = parser.ParsingSequence.Callers.Add(ParsingCallerInfo(parsingSequence, state.Id));
        }
      }
      foreach (ruleParser in Simples)     updateTokens(ruleParser.ParsingSequence);
      foreach (ruleParser in Prefixs)     updateTokens(ruleParser.ParsingSequence);
      foreach (ruleParser in Postfixs)    updateTokens(ruleParser.ParsingSequence);
      foreach (ruleParser in Extensibles) updateTokens(ruleParser.ParsingSequence);

      while (consumeErrorTokensToProcess.Count > 0)
        foreach ((parsingSequence, _) in consumeErrorTokensToProcess.Pop().Callers)
          unless (parsingSequence.CanConsumeErrorTokens)
          {
            parsingSequence.CanConsumeErrorTokens = true;
            consumeErrorTokensToProcess.Push(parsingSequence);
          }
    }

    private CollectFirstTokens(ruleIdBuilder : RuleIdBuilder) : void
    {
      mutable updated = true;
      def updateTokens(parsingSequence : ParsingSequence)
      {
        def count = parsingSequence.FirstTokens.Count;
        foreach (state in parsingSequence.States)
        {
          | Predicate                  => ()
          | Simple               (ruleParser, _)
          | Extensible           (ruleParser, _)
          | DynamicExtensibleItem(ruleParser) =>
            def tokenParser = GetTokenParser(state.SubruleInfo);
            if (tokenParser == null)
              state.FirstTokens.UnionWith(ruleParser.ParsingSequence.FirstTokens);
            else
              _ = state.FirstTokens.Add(tokenParser);

          | ListWithSeparator(seq)
          | Subsequence      (seq, _)
          | List             (seq)
          | DynamicExtensible(seq) =>
            def tokenParser = GetTokenParser(state.SubruleInfo);
            if (tokenParser == null)
            {
              updateTokens(seq);
              state.FirstTokens.UnionWith(seq.FirstTokens);
            }
            else
              _ = state.FirstTokens.Add(tokenParser);

          | Scan              as state =>
            def tokenParser = GetTokenParser(state.SubruleInfo);
            when (tokenParser != null)
              _ = state.FirstTokens.Add(tokenParser);

          | ExtensionPrefix  as state =>
            foreach (parser in state.RuleParser.PrefixRules)
              state.FirstTokens.UnionWith(parser.ParsingSequence.FirstTokens);

          | ExtensionPostfix as state =>
            foreach (parser when state.RuleParser.FirstPostfixRuleId <= parser.RuleId in state.RuleParser.PostfixRules)
              state.FirstTokens.UnionWith(parser.ParsingSequence.FirstTokens);
        }
        foreach (state when state != -1 in parsingSequence.StartStates)
            parsingSequence.FirstTokens.UnionWith(ruleIdBuilder.GetParsingState(state).FirstTokens);
        updated = updated || count != parsingSequence.FirstTokens.Count;
      }
      while (updated)
      {
        updated = false;
        foreach (ruleParser in Simples)     unless (ruleParser.IsTokenRule) updateTokens(ruleParser.ParsingSequence);
        foreach (ruleParser in Prefixs)     unless (ruleParser.IsTokenRule) updateTokens(ruleParser.ParsingSequence);
        foreach (ruleParser in Postfixs)    unless (ruleParser.IsTokenRule) updateTokens(ruleParser.ParsingSequence);
        foreach (ruleParser in Extensibles) unless (ruleParser.IsTokenRule) updateTokens(ruleParser.ParsingSequence);
      }
    }

    private InitTokens() : void
    {
      def simpleVisited = SCG.HashSet();
      def extensibleVisited = SCG.HashSet();
      def visit(sequence)
      {
        foreach (subrule in sequence.Subrules)
        {
          | ListItem                     => assert(false);
          | Option            as subrule => visit(subrule.Rule);
          | List              as subrule => visit(subrule.Item);
          | ListWithSeparator as subrule => visit(subrule.Item);  visit(subrule.Separator);
          | ExtensibleCall    as subrule => visitExtensible(subrule.RuleParser);
          | SimpleCall        as subrule => visitSimple(subrule.RuleParser);
          | TokenString       as subrule => Tokens[subrule.Str]        = TokenParser.TokenString(subrule.Str);
          | Empty | Marker => ()
          | RegularCall       as subrule =>
            if (subrule.Descriptor.IsVoid)
              VoidTokens[subrule.Descriptor] = TokenParser.RegularCall(subrule.Descriptor);
            else
              Tokens[subrule.Descriptor]     = TokenParser.RegularCall(subrule.Descriptor);
        }
      }
      and visitSimple(parser)
      {
        if (parser.IsTokenRule)
        {
          if (parser.IsVoid)
            VoidTokens[parser] = TokenParser.SimpleCall(parser);
          else
            Tokens[parser]     = TokenParser.SimpleCall(parser);
        }
        else when (simpleVisited.Add(parser))
          visit(parser.Reflection(parser.RuleId));
      }
      and visitExtensible(parser)
      {
        if (parser.IsTokenRule)
        {
          if (parser.IsVoid)
            VoidTokens[parser] = TokenParser.ExtensibleCall(parser);
          else
            Tokens[parser]     = TokenParser.ExtensibleCall(parser);
        }
        else when (extensibleVisited.Add(parser))
        {
          foreach (parser in parser.PrefixRules)
            visit(parser.Reflection(parser.RuleId));
          for (mutable i = parser.FirstPostfixRule; i < parser.PostfixRules.Length; ++i)
          {
            def parser = parser.PostfixRules[i];
            visit(parser.Reflection(parser.RuleId));
          }
        }
      }

      foreach ((descriptor, parser) when descriptor.IsStartRule in SimpleRuleParsers.KeyValuePairs)
        visitSimple(parser);

      foreach ((descriptor, parserData) when descriptor.IsStartRule in ExtensibleRules.KeyValuePairs)
        visitExtensible(parserData.GetParser("0"));
    }

    public GetTokenParser(subrule : SubruleInfo) : TokenParser
    {
      def getToken(isVoid : bool, key : object)
      {
        def tokens = if (isVoid) VoidTokens else Tokens;
        mutable token;
        if (tokens.TryGetValue(key, out token)) token else null;
      }
      match (subrule)
      {
        | ExtensibleCall    as subrule =>
          if (subrule.RuleParser.IsTokenRule)
            getToken(subrule.RuleParser.IsVoid, subrule.RuleParser);
          else
            null

        | SimpleCall        as subrule =>
          if (subrule.RuleParser.IsTokenRule)
            getToken(subrule.RuleParser.IsVoid, subrule.RuleParser);
          else
            null

        | TokenString       as subrule => getToken(false, subrule.Str);
        | RegularCall       as subrule =>
          getToken(subrule.Descriptor.IsVoid, subrule.Descriptor);

        | _ => null
      }
    }

    public GetExtensibleRuleParser(rd : ExtensibleRuleDescriptor, bindingPower : string) : ExtensibleRuleParser
    {
      ExtensibleRules[rd].GetParser(bindingPower)
    }

    public GetSimpleRuleParser(rd : SimpleRuleDescriptor) : SimpleRuleParser
    {
      SimpleRuleParsers[rd]
    }

    public GetStartRuleParser(descriptor : StartRuleDescriptor) : StartRuleParser
    {
      match (descriptor)
      {
        | desc is SimpleRuleDescriptor     => GetSimpleRuleParser(desc)
        | desc is ExtensibleRuleDescriptor => GetExtensibleRuleParser(desc, "0")
        | _ => assert3(false, "GetStartRuleParser support only SimpleRuleDescriptor or ExtensibleRuleDescriptor")
      }
    }

    public ParseAllNonVoidGrammarTokens(pos : int, parseResult : ParseResult) : SCG.HashSet[int]
    {
      def text = parseResult.Text;
      def results = SCG.HashSet.[int]();

      foreach (token in Tokens.Values)
        _ = results.Add(token.Parse(pos, text, parseResult));

      results
    }

    public ParseAllVoidGrammarTokens(pos : int, parseResult : ParseResult) : SCG.HashSet[int]
    {
      def text = parseResult.Text;
      def results = SCG.HashSet.[int]();

      foreach (token in VoidTokens.Values)
        _ = results.Add(token.Parse(pos, text, parseResult));

      results
    }

    public Literals : Seq[string]
    {
      get { Tokens.Values.OfType.[TokenParser.TokenString]().Select(t => t.Str) }
    }

    public ParseAllGrammarTokens(pos : int, parseResult : ParseResult) : SCG.HashSet[int]
    {
      parseResult.ParseSession.CancellationToken.ThrowIfCancellationRequested();

      def text = parseResult.Text;
      def results = SCG.HashSet.[int]();

      foreach (token in Tokens.Values)
        _ = results.Add(token.Parse(pos, text, parseResult));

      foreach (token in VoidTokens.Values)
        _ = results.Add(token.Parse(pos, text, parseResult));

      results
    }

    public ParseNonVoidTokens(pos : int, parseResult : ParseResult) : SCG.List[TokenParserApplication]
    {
      parseResult.ParseSession.CancellationToken.ThrowIfCancellationRequested();

      def text = parseResult.Text;
      def results = SCG.List();

      foreach (token in Tokens.Values)
      {
        def newPos = token.Parse(pos, text, parseResult);
        when (newPos > pos)
          results.Add(TokenParserApplication(pos, newPos, false, token));
      }

      results
    }

    public IsVoidToken(parser : object) : bool
    {
      Tokens.ContainsKey(parser) || VoidTokens.ContainsKey(parser)
    }

    public IsExtendedGrammar(that : CompositeGrammar) : bool
    {
      that.Grammars.Count > Grammars.Count && IsExtendedGrammarOrSame(that)
    }

    public IsExtendedGrammarOrSame(that : CompositeGrammar) : bool
    {
      foreach (descriptor in Grammars)
        unless (that.Grammars.Contains(descriptor))
          return false;
      true
    }

    private static HtmlTemplate = @"
<html>
<head>
    <title>Pretty Print</title>
    <meta http-equiv='Content-Type' content='text/html;charset=utf-8'/>
    <style type='text/css'>
pre
{
  color: black;
  font-weight: normal;
  font-size: 12pt;
  font-family: Consolas, Courier New, Monospace;
}

.default
{
  color: black;
  background: white;
}

.keyword
{
  color: Blue;
}

.string
{
  color: Red;
}

.marker
{
  color: LightGray;
}

a:hover
{
  color: DarkBlue;
  font-weight: bold;
  text-decoration: none;
}


.simpleRuleCall
{
  color: DarkBlue;
}

.extensibleRuleCall
{
  color: DarkCyan;
}

.regexRuleCall
{
  color: DarkMagenta;
}

a:visited, a:link, a:active
{
  text-decoration: none;
}
</style>
</head>
<body>
<pre>
<content/>
</pre>
</body>
</html>
";

    public ToHtml() : XElement
    {
      def root       = XElement("span");
      def keywordCss = XAttribute("class", "keyword");
      def stringCss  = XAttribute("class", "string");
      def markerCss  = XAttribute("class", "marker");
      def seqInfoToLabelMap = Hashtable.[RuleDescriptor, string]();
      mutable id = 0;
      def getId()    : int    { id++; id }
      def getLabel(descriptor : RuleDescriptor) : string
      {
        mutable label;
        unless (seqInfoToLabelMap.TryGetValue(descriptor, out label))
        {
          label = "Ref_" + getId();
          seqInfoToLabelMap.Add(descriptor, label);
        }

        label
      }
      def renderAHref(descriptor : RuleDescriptor, text : string) : XElement
      {
        def cssClass =
          match (descriptor)
          {
            | SimpleRuleDescriptor     => "simpleRuleCall"
            | ExtensibleRuleDescriptor => "extensibleRuleCall"
            | RegularRuleDescriptor    => "regexRuleCall"
            | _                        => assert3(false);
          };

        XElement("a", XAttribute("href", "#" + getLabel(descriptor)), XAttribute("class", cssClass), text)
      }
      def convertSubrule(parent : XElement, subrule : SubruleInfo) : void
      {
        def predicates = subrule.HeadPredicates;

        foreach (predicate in predicates)
        {
          parent.Add(if (predicate.IsAnd) "&" else "!");
          renderSubSequence(parent, predicate, suppressParentheses=false);
          parent.Add(" ");
        }

        match (subrule)
        {
          | Empty                  => parent.Add(XElement("span", stringCss, <#""#>));
          | RegularCall       as r =>
            def descriptor = r.Descriptor;
            parent.Add(renderAHref(descriptor, descriptor.Name));

          | ExtensibleCall    as r =>
            def parser = r.RuleParser;
            def bp     = parser.BindingPower;
            parent.Add(renderAHref(parser.Descriptor, parser.Descriptor.Name));
            when (bp != 0)
              parent.Add(" : " + bp);

          | SimpleCall        as r =>
            def parser = r.RuleParser;
            parent.Add(renderAHref(parser.Descriptor, parser.Descriptor.Name));

          | Option            as r => renderSubSequence(parent, r.Rule, suppressParentheses=false); parent.Add("?");
          | ListItem          as _r => assert2(false); assert(false);
          | List              as r => renderSubSequence(parent, r.Item, suppressParentheses=false); parent.Add(if (r.Min > 0) "+" else "*");
          | ListWithSeparator as r =>
            parent.Add("(");
            renderSubSequence(parent, r.Item, suppressParentheses=true);
            parent.Add("; ");
            renderSubSequence(parent, r.Separator, suppressParentheses=true);
            when (r.HangingSeparator)
              parent.Add("; ?");
            parent.Add(if (r.Min > 0) ")+" else ")*");

          | TokenString       as r => parent.Add(XElement("span", stringCss, "\"" + DotUtils.EscapeString(r.Str) + "\""));
          | Marker            as r => parent.Add(XElement("span", markerCss, r.Name));
        }
      }
      and renderSubSequence(result : XElement, info : SequenceInfo, suppressParentheses : bool) : void
      {
        def needParentheses = !suppressParentheses && info.Subrules.Length != 1;
        when (needParentheses)
          result.Add("(");
        convertSubrules(result, info.Subrules);
        when (needParentheses)
          result.Add(")");
      }
      and convertSubrules(parent : XElement, subrules : array[SubruleInfo]) : void
      {
        foreach (subrule in subrules with i)
        {
          when (i != 0)
            parent.Add(" ");
          convertSubrule(parent, subrule);
        }
      }
      def getType(parser : RuleParser) : XElement
      {
        XElement("span", keywordCss, if (parser.IsVoid) "void " else if (parser.IsTokenRule) "token " else "syntax ")
      }
      def ruleHeader(prefix : XElement, parser : RuleParser, name : string, maxNameLen : int = 0) : XElement
      {
        def nameLen = name.Length;
        def title = XAttribute("title", "Syntax module: " + parser.Descriptor.Grammar.FullName
          + ";  Assembly: " + parser.Descriptor.Grammar.GetType().Assembly.FullName);
        def result = XElement("span", XAttribute("id", getLabel(parser.Descriptor)), title);
        result.Add(prefix);
        result.Add(XElement("span", name));
        when (nameLen < maxNameLen)
          result.Add(string(' ', maxNameLen - nameLen));
        result
      }
      def renderPrefix(parser : ExtensionRuleParser, maxNameLen : int) : void
      {
        def (bp, baseRuleDescriptor) = if (parser.Descriptor is PostfixRuleDescriptor as postfix) (postfix.BindingPower, postfix.BaseRule) else ("?", null);
        def info   = parser.Reflection(parser.RuleId) :> SequenceInfo.Root;
        def result = ruleHeader(XElement("span", "  | "), parser, parser.Descriptor.Name, maxNameLen);
        result.Add(" = ");
        when (bp != "?")
        {
          def baseRule = this.ExtensibleRules[baseRuleDescriptor].GetParser("0");
          result.Add(XElement("span", " ", renderAHref(baseRule.Descriptor, baseRule.Descriptor.Name)));
          when (bp != "0")
            result.Add(" : " + bp + " ");
        }
        convertSubrules(result, info.Subrules);
        result.Add(";\r\n");
        root.Add(result);
      }

      def header = XElement("span");
      def assemblies = Grammars.GroupBy(g => g.GetType().Assembly);
      foreach (assembly in assemblies.OrderBy(a => a.Key.FullName))
      {
        header.Add(XElement("span", "Assemby: " + assembly.Key.FullName + "\r\n"));

        foreach (syntaxModule in assembly.OrderBy(m => m.FullName))
          header.Add(XElement("span", "  Syntax module: " + syntaxModule.FullName + "\r\n"));
      }

      header.Add(XElement("span", "\r\n"));

      root.Add(XElement("span", "\r\n"));

      def parsers = SCG.List.[StartRuleParser](Simples);
      parsers.AddRange(Extensibles.Where(e => e.BindingPower == 0));
      def parsers2 = parsers.OrderByDescending(_.IsTokenRule).ThenBy(x => x.Descriptor.Name);

      foreach (parser in parsers2)
      {
        | SimpleRuleParser as parser =>
          when (parser.Reflection(parser.RuleId) is SequenceInfo.Root as info)
          {
            def result = ruleHeader(getType(parser), parser, parser.Descriptor.Name);
            result.Add(" = ");
            convertSubrules(result, info.Subrules);
            result.Add(";\r\n");
            root.Add(result);
          }

        | ExtensibleRuleParser as parser =>
          def result = ruleHeader(getType(parser), parser, parser.Descriptor.Name);
          root.Add(result);
          root.Add("\r\n{\r\n");

          def extensionRules = SCG.List(parser.PrefixRules.OrderBy(r => r.Descriptor.Name));
          extensionRules.AddRange(parser.PostfixRules.OrderBy(r => (r.Descriptor :> PostfixRuleDescriptor).BindingPower).ThenBy(r => r.Descriptor.Name));

          when (extensionRules.Count > 0)
          {
            def maxNameLen = extensionRules.Max(r => r.Descriptor.Name.Length);
            foreach(subParser in extensionRules)
              renderPrefix(subParser, maxNameLen);
          }

          root.Add("}\r\n");

        | _ => assert3(false);
      }

      foreach (descriptor is RegularRuleDescriptor in seqInfoToLabelMap.Keys.Distinct().OrderByDescending(_.Name))
        root.AddFirst(XElement("span", XAttribute("id", getLabel(descriptor)), XElement("span", keywordCss, "regex"), " ", descriptor.Name, " = ", descriptor.RegexText, ";\r\n"));

      root.AddFirst(header);

      def template = XElement.Parse(HtmlTemplate);
      def content = template.Descendants("content").First();
      Debug.Assert(content.Parent != null);
      content.Parent.ReplaceAll(root);
      template
    }
  }
}
