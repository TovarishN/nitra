using Nemerle;
using Nemerle.Collections;
using Nemerle.Imperative;
using Nemerle.Text;
using Nemerle.Utility;
using Nemerle.Extensions;

using Nitra.Runtime;
using Nitra.Runtime.Reflection;

using System;
using System.Diagnostics;
using System.IO;
using System.Linq;

using SCG = System.Collections.Generic;

namespace Nitra.Internal.Recovery
{
  public partial class RecoveryParser
  {
    public ParseResult       : ParseResult;
    public Sequences         : Hashtable[int * ParsingSequence, ParsedSequence] = Hashtable();
    public Records           : array[Hashtable[ParseRecord, TokenChanges]];
    public RecordsToProcess  : Heap[ParseRecord * TokenChanges] = Heap(1024,
      fun ((a, aTokenChanges), (b, bTokenChanges))
      {
        if (b.IsComplete) if (a.IsComplete) 0 else -1
        else              if (a.IsComplete) 1
        else
        {
          def c = (b.Sequence.StartTokenChanges + bTokenChanges).CompareTo(a.Sequence.StartTokenChanges + aTokenChanges);
          if (c != 0)
            c
          else
            b.ParsePos.CompareTo(a.ParsePos)
        }
      });

    public mutable MaxPos       : int = 0;
    public mutable BestSolution : TokenChanges = TokenChanges.Fail;
    public mutable IsRecordsToProcessCorrupted : bool = false;
    public CompletionPos : int;

    public StartSequence : ParsedSequence { get { this.Sequences[0, this.ParseResult.RuleParser.ParsingSequence] } }

    public this(parseResult : IParseResult)
    {
      def parseResultImpl = parseResult :> ParseResult;
      Records       = array(parseResultImpl.Text.Length + 1);
      CompletionPos = parseResultImpl.CompletionPos;
      ParseResult   = parseResultImpl;
    }

    private ErrorPositions : SCG.HashSet[int] = SCG.HashSet();

    public CollectKeywordCompletionList(completionStartPos : int, completionPrefix : string) : void
    {
      return;//TODO fix me
      when (completionStartPos < 0)
        return;

      def len = completionPrefix.Length;
      when (len > 42)
        return;
      def prefix = completionPrefix;
      def i1 = Array.FindIndex(Records, completionStartPos, _ != null);
      def index = if (i1 >= 0) i1 else Array.FindLastIndex(Records, completionStartPos, _ != null);
      when (index < 0)
        return;
      def records = Records[index];
      
      when (records == null)
        return;
        
      def result = SCG.HashSet();
      foreach (record when !record.Key.IsComplete in records)
        match (record.Key.ParsingState)
        {
          | ParsingState.Scan(SubruleInfo = SubruleInfo.TokenString(Str = literal)) =>
            when (literal.StartsWith(prefix, StringComparison.InvariantCultureIgnoreCase))
              _ = result.Add(literal);
              
          | ParsingState.Scan(SubruleInfo = SubruleInfo.RegularCall as c) when !c.Literals.IsEmpty =>
            foreach(literal in c.Literals)
              when (literal.StartsWith(prefix, StringComparison.InvariantCultureIgnoreCase))
                _ = result.Add(literal);
            
          | _ => ()
        }
          
      throw LiteralCompletionException(result.OrderBy(x => x).ToArray())
    }

    public RecoveryFromAllErrors() : void
    {
      def parseSession       = ParseResult.ParseSession;
      def completionPrefix   = parseSession.CompletionPrefix;
      def completionStartPos = CompletionPos;
      def timer = Stopwatch.StartNew();
      def timeout = timer.Elapsed + parseSession.RecoveryTimeout;
      def textPos = 0;
      Records[textPos] = Hashtable();
      match (ParseResult.RuleParser)
      {
        | SimpleRuleParser     as ruleParser => _ = StartParseSequence(textPos, ruleParser.ParsingSequence, TokenChanges.None);
        | ExtensibleRuleParser as ruleParser => _ = StartParseSequence(textPos, ruleParser.ParsingSequence, TokenChanges.None);
        | _                                  => assert3(false)
      }
      Parse();

      unless (BestSolution.IsFail)
        CollectKeywordCompletionList(completionStartPos, completionPrefix);
      
      mutable prevMaxPos = -1;
      while (BestSolution.IsFail)
      {
        ParseToFailPos();
        def curMaxPos = MaxPos;
        prevMaxPos = MaxPos;

        when (completionPrefix != null && MaxPos >= completionStartPos)
          CollectKeywordCompletionList(completionStartPos, completionPrefix);
        
        _ = ErrorPositions.Add(curMaxPos);
        InsertSubrules(curMaxPos);
        //Parse();
        //when (curMaxPos == MaxPos)
          DeleteTokenOrGarbage(curMaxPos, forceDelete = curMaxPos == prevMaxPos);
        //when (RecordsToProcess.Count == 0 && RecordsToComplete.Count == 0)
        //{
        //  BestSolution = BestSolution;
        //  throw Exception("Recovery fail.");
        //}
        Parse();
        when (timer.Elapsed > timeout)
        {
          Delete(curMaxPos, ParseResult.Text.Length);
          Parse();
        }
      }

      SaveRecoveredRawTreePart();
    }

    private ParseToFailPos() : void
    {
      def memoization = SCG.Dictionary();
      def grammar = this.ParseResult.RuleParser.Grammar;

      mutable maxPos;
      do
      {
        maxPos = MaxPos;
        mutable count;
        do
        {
          def records = Records[maxPos].KeyValuePairs.ToArray(); // to materialize collection
          count = records.Length;

          // Находим все состояния которые могут съедать мусор
          foreach ((record, tokenChanges) in records)
            when (record.State >= 0)
              foreach (seq in record.ParsingState.CalleeSequences)
                when (seq.CanConsumeErrorTokens)
                {
                  PredictionOrScanning(record, tokenChanges, false);
                  break;
                }

          def sequences = SCG.HashSet(Records[maxPos].Keys.Select(r => r.Sequence));
          foreach (sequence when sequence.ParsingSequence.SequenceInfo != null in sequences)
          {
            when (IsInsideToken(memoization, grammar, sequence) && !sequence.ParsingSequence.CanConsumeErrorTokens)
              continue;
            foreach ((subrule, _) in sequence.ParsedSubrules.KeyValuePairs.NToArray())//TODO optimize
              when (subrule.State >= 0 && subrule.End == maxPos)
              {
                def record = ParseRecord(sequence, subrule.State, subrule.Begin);
                PredictionOrScanning(record, Records[record.ParsePos][record], false);
              }
          }
          Parse();
        }
        while (count < Records[maxPos].Count);
      }
      while (maxPos < MaxPos);
    }

    private static IsInsideToken(memoization : SCG.Dictionary[ParsedSequence, bool], compositeGrammar : CompositeGrammar, seq : ParsedSequence) : bool
    {
      mutable res;
      when (memoization.TryGetValue(seq, out res))
        return res;

      when (seq.ParsingSequence.SequenceInfo is SequenceInfo.Root)
      {
        def parser = seq.ParsingSequence.SequenceInfo.Parser;
        res = compositeGrammar.IsVoidToken(parser);
        memoization[seq] = res;
        when (res)
          return res;
      }

      foreach (caller in seq.Callers)
      {
        res = IsInsideToken(memoization, compositeGrammar, caller.Sequence);
        when (res)
        {
          memoization[seq] = true;
          return true;
        }
      }

      memoization[seq] = false;
      false
    }

    internal static ParsingOrderSubrulesComparison : Comparison[ParsedSubrule * TokenChanges] = ((l, _), (r, _)) =>
    {
      res:
        {
          mutable c;
          c = l.Begin.CompareTo(r.Begin); when (c != 0) res(c);
          c = l.End.CompareTo(r.End); when (c != 0) res(c);
          l.State.CompareTo(r.State);
        }
    };
  }
}
